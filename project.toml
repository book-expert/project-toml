# ========================================================================
# GLOBAL PROJECT CONFIGURATION
# This file serves as the single source of truth for all microservices.
# ========================================================================

[project]
name = "unified-document-processing-system"
version = "1.0.0"
description = "A system for processing documents from PDF to text and speech, with AI augmentation."

[paths]
base_logs_dir = "/tmp/logs"

# ========================================================================
# BOOK-EXPERT-SERVICE SPECIFIC CONFIGURATION
# ========================================================================
[book_expert_service]
log_directory = "/tmp/logs"
log_filename = "book-expert-service.log"
watchdog_interval_seconds = 60
required_units = [
    "nats-server.service",
    "user-database.service"
]

[database]
user_database_dsn = "postgres://book_expert_user:b00k_3xp3rt@localhost:5432/book_expert_db"

[ui_service]
http_address = ":8080"
max_upload_megabytes = 64

[png_to_text_service.prompts]
commentary_base = """

## ROLE AND GOAL
You are a technical editor preparing a raw document script for an audiobook narrator. Your goal is to create a clean, seamless, narration-ready script by augmenting the provided text with descriptions of its visual elements. This is an **augmentation** task, not a summarization task. Think of yourself as an accessibility narrator describing a scene for the visually impaired; you are adding the missing visual context.

---
## CRITICAL RULES
1.  **PRESERVE PROSE:** You MUST preserve the original prose. Do not summarize or significantly rephrase the text. Your only job is to clean up OCR artifacts and add descriptions for non-textual content.
2.  **NO HEADERS OR MARKDOWN:** The final output MUST be a single, continuous block of text. Do not use markdown, titles, or section headers.
3.  **NO EXPLICIT REFERENCES:** When describing a visual, weave the description directly and naturally into the narrative. NEVER say "The image shows..." or "Figure 1 contains...".
4.  **NO NARRATOR FLUFF:** Do not add conversational filler like "Welcome to the chapter" or "In this section, we will...". Stick to the source material.

---
## 3-STEP PROCESS
1.  **Clean Artifacts:** First, remove all headers, footers, and page numbers found in the OCR text. Integrate section titles (e.g., "Introduction") smoothly as the start of a new paragraph.
2.  **Augment with Visuals:** At the exact point where a visual element (figure, table, code block, formula, etc.) appears in the original document, insert a concise, natural-language description of its content. This is your primary task.
3.  **Format for Narration:** Handle acronyms for the narrator. The first time an acronym appears, write the full term followed by the acronym in parentheses, like "Peripheral Component Interface (PCI)". For ALL subsequent uses, format it with periods to signal that it should be spelled out: "P. C. I.".
"""

summary_base = """

## ROLE AND GOAL
You craft concise previews or recaps that help a listener understand the purpose of the upcoming page. Capture the central ideas, the structure of the argument, and the outcome of any computations or examples.

---
## CRITICAL RULES
1. Keep the summary to two or three natural sentences focused on intent and outcomes.
2. Highlight the purpose of major visuals or data displays without restating fine-grained commentary details.
3. Use clear prose with no markdown, bullets, or section headers.
4. After the summary, present the original OCR text exactly once; do not paraphrase or omit content.

---
## STRUCTURE
Open with the most important conclusion or question answered on the page. Mention secondary points or transitions that prepare the listener for what follows. Close by signalling how the listener should expect the narration to proceed (e.g., "The next section dives into..." when appropriate).
"""

[png_to_text_service.augmentation]
use_prompt_builder = true
parameters = {}

[png_to_text_service.augmentation.defaults.commentary]
enabled = true
custom_additions = ""

[png_to_text_service.augmentation.defaults.summary]
enabled = false
placement = "bottom"
custom_additions = ""

[png_to_text_service.gemini]
api_key_variable = "${GEMINI_API_KEY}"

[png_to_text_service.tts_defaults]
voice = "tara"
seed = 10
ngl = 8
top_p = 0.95
repetition_penalty = 1.1
temperature = 0.70

# ========================================================================
# TTS-SERVICE SPECIFIC CONFIGURATION
# ========================================================================
[tts_service]
model_path = "${TTS_MODEL_PATH}"
snac_model_path = "${SNAC_MODEL_PATH}"
seed = 10
ngl = 8
voice = "tara"
temperature = 0.70
top_p = 0.95
repetition_penalty = 1.1
timeout_seconds = 300
allowed_voices = ["default", "tara", "leah", "jess", "leo", "dan", "mia", "zac", "zoe"]
dead_letter_subject = "book-expert.tts.dlq"

# ========================================================================
# PCM-TO-WAV-SERVICE SPECIFIC CONFIGURATION
# ========================================================================
[pcm_to_wav_service]
[pcm_to_wav_service.sox]
encoding = "signed-integer"
bits = 16
rate = 24000
channels = 1
input_type = "raw"
output_type = "wav"

# ========================================================================
# WAV-AGGREGATOR-SERVICE SPECIFIC CONFIGURATION
# ========================================================================
[wav_aggregator_service]
worker_pool_size = 10
dead_letter_subject = "book-expert.wav-aggregator.dlq"

# ========================================================================
# USER-DATABASE-SERVICE SPECIFIC CONFIGURATION
# ========================================================================
[user_database_service]
base_url = "http://localhost:8085"
listen_address = "0.0.0.0:8085"
jwt_issuer = "book-expert-user-db"
jwt_audience = "book-expert"
access_token_ttl_minutes = 15
refresh_token_ttl_hours = 720
argon2_memory_kib = 19456
argon2_iterations = 3
argon2_parallelism = 1

# ========================================================================
# CONFIGURATOR SERVICE SPECIFIC CONFIGURATION
# (No specific configuration needed for configurator itself, it's a library)
# ========================================================================

[cost_estimator_service]
currency = "USD"
page_block_size = 100
base_rate_cents_per_block = 200
default_augmentation_cents_per_block = 50
custom_commentary_cents_per_block = 100
custom_summary_cents_per_block = 100
maximum_prompt_characters = 500

[nats]
url = "nats://127.0.0.1:4222"

[pdf-to-png-service.nats]
    streams = [
      { name = "pdfs", subjects = ["book-expert.pdfs.created"] },
      { name = "pngs", subjects = ["book-expert.pngs.created"] }
    ]
    consumers = [
      { stream_name = "pdfs", consumer_name = "pdf-to-png-consumer", filter_subject = "book-expert.pdfs.created" }
    ]
    object_stores = [
      { bucket_name = "pdf-files" },
      { bucket_name = "png-files" }
    ]

[png-to-text-service.nats]
    streams = [
      { name = "pngs", subjects = ["book-expert.pngs.created"] },
      { name = "texts", subjects = ["book-expert.texts.created"] }
    ]
    consumers = [
      { stream_name = "pngs", consumer_name = "png-to-text-consumer", filter_subject = "book-expert.pngs.created" }
    ]
    object_stores = [
      { bucket_name = "png-files" },
      { bucket_name = "text-files" }
    ]

# ------------------------------------------------------------------------
# TEXT TO SPEECH SERVICE
# Consumes: Text files
# Produces: Audio chunks (PCM)
# ------------------------------------------------------------------------
tts_stream_name = "TTS_JOBS"
tts_consumer_name = "tts-workers"
text_processed_subject = "text.processed"
audio_chunk_created_subject = "audio.chunk.created"
audio_object_store_bucket = "AUDIO_FILES"

# ------------------------------------------------------------------------
# PCM TO WAV SERVICE
# Consumes: Audio chunks (PCM)
# Produces: WAV files
# ------------------------------------------------------------------------
audio_processing_stream_name = "AUDIO_PROCESSING"
audio_processing_consumer_name = "pcm-to-wav-workers"
wav_created_subject = "wav.created"
wav_object_store_bucket = "WAV_FILES"

# ------------------------------------------------------------------------
# WAV AGGREGATOR SERVICE
# Consumes: WAV files
# Produces: Final aggregated audio
# ------------------------------------------------------------------------
final_audio_created_subject = "final.audio.created"
final_audio_object_store_bucket = "FINAL_AUDIO_FILES"
wav_consumer_name = "wav-aggregator-workers"
wav_aggregator_kv_bucket = "WAV_AGGREGATOR_STATE"
