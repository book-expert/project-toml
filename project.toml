# ========================================================================
# GLOBAL CONFIGURATION
# ========================================================================

[project]
name = "unified-document-processing-system"
version = "1.0.0"
description = "A system for processing documents from PDF to text and speech, with AI augmentation."

[paths]
base_logs_dir = "/tmp/logs"

[nats]
url = "nats://127.0.0.1:4222"

[database]
user_database_dsn = "postgres://book_expert_user:b00k_3xp3rt@localhost:5432/book_expert_db"

# ========================================================================
# BOOK EXPERT SERVICE (Main Orchestrator)
# ========================================================================

[book_expert_service]
log_directory = "/tmp/logs"
log_filename = "book-expert-service.log"
watchdog_interval_seconds = 60
required_units = [
    "nats-server.service",
    "user-database.service"
]

# ========================================================================
# COST ESTIMATOR SERVICE
# ========================================================================

[cost_estimator_service]
currency = "USD"
page_block_size = 100
base_rate_cents_per_block = 200
default_augmentation_cents_per_block = 50
custom_commentary_cents_per_block = 100
custom_summary_cents_per_block = 100
maximum_prompt_characters = 500

# ========================================================================
# PDF TO PNG SERVICE
# ========================================================================
# Role: Consumer of PDFs, Producer of PNGs
# Consumes: book-expert.pdfs.created
# Produces: book-expert.pngs.created
# ========================================================================

[pdf_to_png_service]
dead_letter_subject = "book-expert.pdf-to-png.dlq"

[pdf_to_png_service.nats]
    # Streams this service interacts with
    streams = [
      { name = "PDFS", subjects = ["book-expert.pdfs.created"] },
      { name = "PNGS", subjects = ["book-expert.pngs.created"] },
      { name = "PDF_TO_PNG_DLQ", subjects = ["book-expert.pdf-to-png.dlq"] }
    ]
    
    # Consumer configuration - what this service listens to
    consumers = [
      { 
        stream_name = "PDFS", 
        consumer_name = "pdf-to-png-consumer", 
        filter_subject = "book-expert.pdfs.created",
        durable_name = "pdf-to-png-durable",
        ack_policy = "explicit",
        max_deliver = 3
      }
    ]
    
    # Producer configuration - what this service publishes to
    producers = [
      { subject = "book-expert.pngs.created", stream = "PNGS" }
    ]
    
    # Object store buckets for file storage
    object_stores = [
      { bucket_name = "PDF_FILES" },
      { bucket_name = "PNG_FILES" }
    ]

# ========================================================================
# PNG TO TEXT SERVICE (OCR + AI Augmentation)
# ========================================================================
# Role: Consumer of PNGs, Producer of Texts
# Consumes: book-expert.pngs.created
# Produces: book-expert.texts.created
# ========================================================================

[png_to_text_service]
dead_letter_subject = "book-expert.png-to-text.dlq"

[png_to_text_service.prompts]
commentary_base = """

## ROLE AND GOAL
You are a technical editor preparing a raw document script for an audiobook narrator. Your goal is to create a clean, seamless, narration-ready script by augmenting the provided text with descriptions of its visual elements. This is an **augmentation** task, not a summarization task. Think of yourself as an accessibility narrator describing a scene for the visually impaired; you are adding the missing visual context.

---
## CRITICAL RULES
1.  **PRESERVE PROSE:** You MUST preserve the original prose. Do not summarize or significantly rephrase the text. Your only job is to clean up OCR artifacts and add descriptions for non-textual content.
2.  **NO HEADERS OR MARKDOWN:** The final output MUST be a single, continuous block of text. Do not use markdown, titles, or section headers.
3.  **NO EXPLICIT REFERENCES:** When describing a visual, weave the description directly and naturally into the narrative. NEVER say "The image shows..." or "Figure 1 contains...".
4.  **NO NARRATOR FLUFF:** Do not add conversational filler like "Welcome to the chapter" or "In this section, we will...". Stick to the source material.

---
## 3-STEP PROCESS
1.  **Clean Artifacts:** First, remove all headers, footers, and page numbers found in the OCR text. Integrate section titles (e.g., "Introduction") smoothly as the start of a new paragraph.
2.  **Augment with Visuals:** At the exact point where a visual element (figure, table, code block, formula, etc.) appears in the original document, insert a concise, natural-language description of its content. This is your primary task.
3.  **Format for Narration:** Handle acronyms for the narrator. The first time an acronym appears, write the full term followed by the acronym in parentheses, like "Peripheral Component Interface (PCI)". For ALL subsequent uses, format it with periods to signal that it should be spelled out: "P. C. I.".
"""

summary_base = """

## ROLE AND GOAL
You craft concise previews or recaps that help a listener understand the purpose of the upcoming page. Capture the central ideas, the structure of the argument, and the outcome of any computations or examples.

---
## CRITICAL RULES
1. Keep the summary to two or three natural sentences focused on intent and outcomes.
2. Highlight the purpose of major visuals or data displays without restating fine-grained commentary details.
3. Use clear prose with no markdown, bullets, or section headers.
4. After the summary, present the original OCR text exactly once; do not paraphrase or omit content.

---
## STRUCTURE
Open with the most important conclusion or question answered on the page. Mention secondary points or transitions that prepare the listener for what follows. Close by signalling how the listener should expect the narration to proceed (e.g., "The next section dives into..." when appropriate).
"""

[png_to_text_service.augmentation]
use_prompt_builder = true
parameters = {}

[png_to_text_service.augmentation.defaults.commentary]
enabled = true
custom_additions = ""

[png_to_text_service.augmentation.defaults.summary]
enabled = false
placement = "bottom"
custom_additions = ""

[png_to_text_service.gemini]
api_key_variable = "${GEMINI_API_KEY}"

[png_to_text_service.tts_defaults]
voice = "tara"
seed = 10
ngl = 8
top_p = 0.95
repetition_penalty = 1.1
temperature = 0.70

[png_to_text_service.nats]
    # Streams this service interacts with
    streams = [
      { name = "PNGS", subjects = ["book-expert.pngs.created"] },
      { name = "TEXTS", subjects = ["book-expert.texts.created"] },
      { name = "PNG_TO_TEXT_DLQ", subjects = ["book-expert.png-to-text.dlq"] }
    ]
    
    # Consumer configuration - what this service listens to
    consumers = [
      { 
        stream_name = "PNGS", 
        consumer_name = "png-to-text-consumer", 
        filter_subject = "book-expert.pngs.created",
        durable_name = "png-to-text-durable",
        ack_policy = "explicit",
        max_deliver = 3
      }
    ]
    
    # Producer configuration - what this service publishes to
    producers = [
      { subject = "book-expert.texts.created", stream = "TEXTS" }
    ]
    
    # Object store buckets for file storage
    object_stores = [
      { bucket_name = "PNG_FILES" },
      { bucket_name = "TEXT_FILES" }
    ]

# ========================================================================
# TTS SERVICE (Text-to-Speech)
# ========================================================================
# Role: Consumer of Texts, Producer of Audio Chunks (PCM)
# Consumes: book-expert.texts.created
# Produces: book-expert.audio.chunk.created
# ========================================================================

[tts_service]
model_path = "${TTS_MODEL_PATH}"
snac_model_path = "${SNAC_MODEL_PATH}"
seed = 10
ngl = 8
voice = "tara"
temperature = 0.70
top_p = 0.95
repetition_penalty = 1.1
timeout_seconds = 300
allowed_voices = ["default", "tara", "leah", "jess", "leo", "dan", "mia", "zac", "zoe"]
dead_letter_subject = "book-expert.tts.dlq"

[tts_service.nats]
    # Streams this service interacts with
    streams = [
      { name = "TEXTS", subjects = ["book-expert.texts.created"] },
      { name = "AUDIO_CHUNKS", subjects = ["book-expert.audio.chunk.created"] },
      { name = "TTS_DLQ", subjects = ["book-expert.tts.dlq"] }
    ]
    
    # Consumer configuration - what this service listens to
    consumers = [
      { 
        stream_name = "TEXTS", 
        consumer_name = "tts-workers", 
        filter_subject = "book-expert.texts.created",
        durable_name = "tts-durable",
        ack_policy = "explicit",
        max_deliver = 3,
        max_ack_pending = 100
      }
    ]
    
    # Producer configuration - what this service publishes to
    producers = [
      { subject = "book-expert.audio.chunk.created", stream = "AUDIO_CHUNKS" }
    ]
    
    # Object store buckets for file storage
    object_stores = [
      { bucket_name = "AUDIO_FILES" }
    ]

# ========================================================================
# PCM TO WAV SERVICE (Audio Format Conversion)
# ========================================================================
# Role: Consumer of Audio Chunks (PCM), Producer of WAV files
# Consumes: book-expert.audio.chunk.created
# Produces: book-expert.wav.created
# ========================================================================

[pcm_to_wav_service]
dead_letter_subject = "book-expert.pcm-to-wav.dlq"

[pcm_to_wav_service.sox]
encoding = "signed-integer"
bits = 32
rate = 24000
channels = 1
input_type = "raw"
output_type = "wav"

[pcm_to_wav_service.nats]
    # Streams this service interacts with
    streams = [
      { name = "AUDIO_CHUNKS", subjects = ["book-expert.audio.chunk.created"] },
      { name = "WAV_FILES", subjects = ["book-expert.wav.created"] },
      { name = "PCM_TO_WAV_DLQ", subjects = ["book-expert.pcm-to-wav.dlq"] }
    ]
    
    # Consumer configuration - what this service listens to
    consumers = [
      { 
        stream_name = "AUDIO_CHUNKS", 
        consumer_name = "pcm-to-wav-workers", 
        filter_subject = "book-expert.audio.chunk.created",
        durable_name = "pcm-to-wav-durable",
        ack_policy = "explicit",
        max_deliver = 3
      }
    ]
    
    # Producer configuration - what this service publishes to
    producers = [
      { subject = "book-expert.wav.created", stream = "WAV_FILES" }
    ]
    
    # Object store buckets for file storage
    object_stores = [
      { bucket_name = "AUDIO_FILES" },
      { bucket_name = "WAV_FILES" }
    ]

# ========================================================================
# WAV AGGREGATOR SERVICE (Final Audio Assembly)
# ========================================================================
# Role: Consumer of WAV files, Producer of Final Audio
# Consumes: book-expert.wav.created
# Produces: book-expert.final.audio.created
# ========================================================================

[wav_aggregator_service]
worker_pool_size = 10
dead_letter_subject = "book-expert.wav-aggregator.dlq"

[wav_aggregator_service.nats]
    # Streams this service interacts with
    streams = [
      { name = "WAV_FILES", subjects = ["book-expert.wav.created"] },
      { name = "FINAL_AUDIO", subjects = ["book-expert.final.audio.created"] },
      { name = "WAV_AGGREGATOR_DLQ", subjects = ["book-expert.wav-aggregator.dlq"] }
    ]
    
    # Consumer configuration - what this service listens to
    consumers = [
      { 
        stream_name = "WAV_FILES", 
        consumer_name = "wav-aggregator-workers", 
        filter_subject = "book-expert.wav.created",
        durable_name = "wav-aggregator-durable",
        ack_policy = "explicit",
        max_deliver = 3,
        max_ack_pending = 50
      }
    ]
    
    # Producer configuration - what this service publishes to
    producers = [
      { subject = "book-expert.final.audio.created", stream = "FINAL_AUDIO" }
    ]
    
    # Object store buckets for file storage
    object_stores = [
      { bucket_name = "FINAL_AUDIO_FILES" }
    ]
    
    # Key-value store for aggregation state management
    key_value = { bucket_name = "WAV_AGGREGATOR_STATE" }

# ========================================================================
# UI SERVICE (Web Interface)
# ========================================================================

[ui_service]
http_address = ":8080"
max_upload_megabytes = 64

# ========================================================================
# USER DATABASE SERVICE (Authentication & Authorization)
# ========================================================================

[user_database_service]
base_url = "http://localhost:8085"
listen_address = "0.0.0.0:8085"
jwt_issuer = "book-expert-user-db"
jwt_audience = "book-expert"
access_token_ttl_minutes = 15
refresh_token_ttl_hours = 720
argon2_memory_kib = 19456
argon2_iterations = 3
argon2_parallelism = 1
